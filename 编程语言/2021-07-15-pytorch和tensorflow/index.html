<!DOCTYPE html><html lang="zh-CN"><head><!-- hexo injector head_begin start --><link href="/css/tag-common/index.css" rel="stylesheet"/><!-- hexo injector head_begin end --><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#6200ee"><meta name="author" content="larry"><meta name="copyright" content="larry"><meta name="generator" content="Hexo 5.4.0"><meta name="theme" content="hexo-theme-yun"><title>pytorch | æ‹‰ç‘å›ã®å°çª</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.25/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_dxory92pb0h.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link class="aplayer-style-marker" rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.css"><script class="aplayer-script-marker" src="https://cdn.jsdelivr.net/npm/aplayer@latest/dist/APlayer.min.js" defer></script><script class="meting-script-marker" src="https://cdn.jsdelivr.net/npm/meting@1/dist/Meting.min.js" defer></script><script>document.addEventListener(
  "pjax:success",
  function() {
    if (window.aplayers) {
      loadMeting();
    }
  },
  !1
);
</script><link id="light-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism.css" media="(prefers-color-scheme: light)"><link id="dark-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism-tomorrow.css" media="(prefers-color-scheme: dark)"><link rel="icon" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#6200ee"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"larrystd.github.io","root":"/","title":"æ‹‰ç‘å›ã®å°çª","version":"1.6.3","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"æœç´¢...","empty":"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹: ${query}","hits":"æ‰¾åˆ° ${hits} æ¡ç»“æœ","hits_time":"æ‰¾åˆ° ${hits} æ¡ç»“æœï¼ˆç”¨æ—¶ ${time} æ¯«ç§’ï¼‰"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"algolia":{"appID":"CJXXAGRCYN","apiKey":"ae1966d2aeab22bf9335679f45d2cd9a","indexName":"my-hexo-blog","hits":{"per_page":8}},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><link rel="alternate" href="/atom.xml" title="æ‹‰ç‘å›ã®å°çª" type="application/atom+xml"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin><script async src="https://www.googletagmanager.com/gtag/js?id=G-1LL0D86CY9"></script><script>if (CONFIG.hostname === location.hostname) {
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-1LL0D86CY9');
}</script><script data-ad-client="ca-pub-2245427233262012" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(function(){
  var bp = document.createElement('script');
  var curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https') {
    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else {
    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})();</script><!-- Google Tag Manager --><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-M9KWR9L');</script><!-- End Google Tag Manager --><meta name="description" content="pytorchåŸºæœ¬çŸ¥è¯†åˆ›å»ºå’Œæ“ä½œTensor import torch print(&quot;ç‰ˆæœ¬å·ä¸º: &amp;#123;&amp;#125;&quot;.format(torch.__version__))  tensor_a &#x3D; torch.arange(0,12) print (tensor_a)  print (&quot;å¼ é‡å­˜å‚¨ä½ç½®: &amp;#123;&amp;#125;&quot;.format">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch">
<meta property="og:url" content="https://larrystd.github.io/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/2021-07-15-pytorch%E5%92%8Ctensorflow/index.html">
<meta property="og:site_name" content="æ‹‰ç‘å›ã®å°çª">
<meta property="og:description" content="pytorchåŸºæœ¬çŸ¥è¯†åˆ›å»ºå’Œæ“ä½œTensor import torch print(&quot;ç‰ˆæœ¬å·ä¸º: &amp;#123;&amp;#125;&quot;.format(torch.__version__))  tensor_a &#x3D; torch.arange(0,12) print (tensor_a)  print (&quot;å¼ é‡å­˜å‚¨ä½ç½®: &amp;#123;&amp;#125;&quot;.format">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-07-15T16:00:00.000Z">
<meta property="article:modified_time" content="2021-07-15T16:00:00.000Z">
<meta property="article:author" content="larry">
<meta property="article:tag" content="python">
<meta property="article:tag" content="æœºå™¨å­¦ä¹ ">
<meta name="twitter:card" content="summary"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="æ–‡ç« ç›®å½•"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="ç«™ç‚¹æ¦‚è§ˆ"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="larry"><img width="96" loading="lazy" src="/images/avatar.jpg" alt="larry"><span class="site-author-status" title="Looking for you.">ğŸŒ‘</span></a><div class="site-author-name"><a href="/about/">larry</a></div><a class="site-name" href="/about/site.html">æ‹‰ç‘å›ã®å°çª</a><sub class="site-subtitle"></sub><div class="site-desciption">æ¯å¤©éƒ½æ˜¯æ–°çš„ä¸€å¤©å‘¢</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="é¦–é¡µ"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="å½’æ¡£"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">86</span></a></div><div class="site-state-item"><a href="/categories/" title="åˆ†ç±»"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">13</span></a></div><div class="site-state-item"><a href="/tags/" title="æ ‡ç­¾"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">42</span></a></div><a class="site-state-item hty-icon-button" href="/about/#comment" title="ç•™è¨€æ¿"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-clipboard-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/larrystd" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.zhihu.com/people/bu-qu-dou-yin-bu-gai-ming" title="çŸ¥ä¹" target="_blank" style="color:#0084FF"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhihu-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="Venray.Kong@outlook.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://travellings.link" title="Travelling" target="_blank" style="color:var(--hty-text-color)"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-train-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="æˆ‘çš„å°ä¼™ä¼´ä»¬" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a><a class="links-item hty-icon-button" href="/girls/" title="å–œæ¬¢çš„å¥³å­©å­" style="color:hotpink"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-women-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#pytorch"><span class="toc-number">1.</span> <span class="toc-text">pytorch</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86"><span class="toc-number">1.1.</span> <span class="toc-text">åŸºæœ¬çŸ¥è¯†</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%84%E9%80%A0"><span class="toc-number">2.</span> <span class="toc-text">æ¨¡å‹æ„é€ </span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">2.1.</span> <span class="toc-text">çº¿æ€§å›å½’</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#softmax%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.</span> <span class="toc-text">softmaxæ¨¡å‹</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%A7%E6%89%BFMudule%E7%B1%BB%E6%9D%A5%E6%9E%84%E9%80%A0%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.</span> <span class="toc-text">ç»§æ‰¿Muduleç±»æ¥æ„é€ æ¨¡å‹</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GPU%E8%AE%A1%E7%AE%97"><span class="toc-number">2.4.</span> <span class="toc-text">GPUè®¡ç®—</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RNN"><span class="toc-number">2.5.</span> <span class="toc-text">RNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="toc-number">2.6.</span> <span class="toc-text">æ³¨æ„åŠ›æœºåˆ¶</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%96%E7%A0%81%E5%99%A8%E5%92%8C%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="toc-number">2.7.</span> <span class="toc-text">ç¼–ç å™¨å’Œè§£ç å™¨</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="https://larrystd.github.io/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/2021-07-15-pytorch%E5%92%8Ctensorflow/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="larry"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="æ‹‰ç‘å›ã®å°çª"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">pytorch<a class="post-edit-link" href="https://github.com/larrystd/larrystd.github.io/tree/hexo/source/_posts/ç¼–ç¨‹è¯­è¨€/2021-07-15-pytorchå’Œtensorflow.md" target="_blank" title="ç¼–è¾‘" rel="noopener"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-edit-line"></use></svg></a></h1><div class="post-meta"><div class="post-time" style="display:block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="åˆ›å»ºæ—¶é—´ï¼š2021-07-16 00:00:00" itemprop="dateCreated datePublished" datetime="2021-07-16T00:00:00+08:00">2021-07-16</time></div><span class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="æœ¬æ–‡å­—æ•°"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="æœ¬æ–‡å­—æ•°">4.2k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="é˜…è¯»æ—¶é•¿"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="é˜…è¯»æ—¶é•¿">21m</span></span></span><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/language/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">language</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/tags/python/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">python</span></a><a class="tag-item" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">æœºå™¨å­¦ä¹ </span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#6200ee;"><h3 id="pytorch"><a href="#pytorch" class="headerlink" title="pytorch"></a>pytorch</h3><h4 id="åŸºæœ¬çŸ¥è¯†"><a href="#åŸºæœ¬çŸ¥è¯†" class="headerlink" title="åŸºæœ¬çŸ¥è¯†"></a>åŸºæœ¬çŸ¥è¯†</h4><p>åˆ›å»ºå’Œæ“ä½œTensor</p>
<pre class="language-py" data-language="py"><code class="language-py">import torch
print(&quot;ç‰ˆæœ¬å·ä¸º: &#123;&#125;&quot;.format(torch.__version__))

tensor_a &#x3D; torch.arange(0,12)
print (tensor_a)

print (&quot;å¼ é‡å­˜å‚¨ä½ç½®: &#123;&#125;&quot;.format(tensor_a.device))

tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
å¼ é‡å­˜å‚¨ä½ç½®: cpu

tensor_a &#x3D; torch.arange(0,12)
print (tensor_a)

print (&quot;å¼ é‡å­˜å‚¨ä½ç½®: &#123;&#125;&quot;.format(tensor_a.device))

print (tensor_a.shape)

print (torch.zeros((2,3,4)))

print (torch.tensor([[1,2],[3,4]]))

print (torch.randn((3,4)))

torch.Size([12])
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])
tensor([[1, 2],
        [3, 4]])
tensor([[-0.7588, -0.7888, -0.3240, -0.1797],
        [ 0.2589,  0.0594,  1.4420, -0.0355],
        [-0.7512,  0.7934,  2.4866, -0.5525]])

X &#x3D; torch.Tensor([[1,2],[3,4],[5,6]])
Y &#x3D; torch.Tensor([[11,12],[13,14],[15,16]])
Z &#x3D; torch.Tensor([[2,3,4],[5,6,7]])

X+Y
X*Y 
X.float()&#x2F;Y.float()
torch.exp(Y.float())
X @ Z  # çŸ©é˜µä¹˜æ³•

torch.cat((X, Y), 0)

tensor([[ 1.,  2.],
        [ 3.,  4.],
        [ 5.,  6.],
        [11., 12.],
        [13., 14.],
        [15., 16.]])

æ¡ä»¶åˆ¤åˆ«å¼ï¼Œå¾—åˆ°å¯¹åº”ä½ç½®å…ƒç´ ä¸º0æˆ–1çš„Tensor
X &#x3D;&#x3D; Y
tensor([[False, False],
        [False, False],
        [False, False]])

torch.sum(X)
tensor(21.)

item() å‡½æ•°å°†å•å…ƒç´ çš„tensorè½¬æ¢ä¸ºæ ‡é‡, normèŒƒæ•°
torch.norm(X).item()

.viem() ç›¸å½“äºnumpyçš„reshape

å½“ç„¶tensorä¹Ÿæ˜¯å¯ç”¨åˆ‡ç‰‡çš„</code></pre>

<span id="more"></span>

<p>reshapeå’Œview</p>
<p>torchçš„view()ä¸reshape()æ–¹æ³•éƒ½å¯ä»¥ç”¨æ¥é‡å¡‘tensorçš„shapeï¼ŒåŒºåˆ«å°±æ˜¯ä½¿ç”¨çš„æ¡ä»¶ä¸ä¸€æ ·ã€‚view()æ–¹æ³•åªé€‚ç”¨äºæ»¡è¶³è¿ç»­æ€§æ¡ä»¶çš„tensorï¼Œå¹¶ä¸”è¯¥æ“ä½œä¸ä¼šå¼€è¾Ÿæ–°çš„å†…å­˜ç©ºé—´ï¼Œåªæ˜¯äº§ç”Ÿäº†å¯¹åŸå­˜å‚¨ç©ºé—´çš„ä¸€ä¸ªæ–°åˆ«ç§°å’Œå¼•ç”¨ï¼Œè¿”å›å€¼æ˜¯è§†å›¾ã€‚è€Œreshape()æ–¹æ³•çš„è¿”å›å€¼æ—¢å¯ä»¥æ˜¯è§†å›¾ï¼Œä¹Ÿå¯ä»¥æ˜¯å‰¯æœ¬ï¼Œå½“æ»¡è¶³è¿ç»­æ€§æ¡ä»¶æ—¶è¿”å›viewï¼Œå¦åˆ™è¿”å›å‰¯æœ¬</p>
<p>tensorä¸numpyè½¬æ¢ </p>
<pre class="language-py" data-language="py"><code class="language-py">import numpy as np
p &#x3D; np.ones((2,3))
d &#x3D; torch.from_numpy(p)

d.numpy()</code></pre>

<p>è‡ªåŠ¨æ±‚æ¢¯åº¦</p>
<pre class="language-py" data-language="py"><code class="language-py">
import torch
from torch import autograd

x &#x3D; torch.arange(4).float()


x.requires_grad_(True)

y &#x3D; 2*x@x.t()

# y - 2 * torch.dot(x, x.t())
y

y.backward()

print (x.grad)

# ç»“æœ
tensor([ 0.,  4.,  8., 12.])

2*x*x å¯¹xçš„æ¢¯åº¦ä¸º4x, ç»“æœä¸ºæ­£ç¡®çš„</code></pre>

<h3 id="æ¨¡å‹æ„é€ "><a href="#æ¨¡å‹æ„é€ " class="headerlink" title="æ¨¡å‹æ„é€ "></a>æ¨¡å‹æ„é€ </h3><h4 id="çº¿æ€§å›å½’"><a href="#çº¿æ€§å›å½’" class="headerlink" title="çº¿æ€§å›å½’"></a>çº¿æ€§å›å½’</h4><pre class="language-py" data-language="py"><code class="language-py"># çº¿æ€§å›å½’ï¼Œæ•°æ®é›†å‡†å¤‡
import matplotlib.pyplot as plt 
import random
import numpy as np
import torch 

num_inputs &#x3D; 2
num_examples &#x3D; 1000
true_w &#x3D; [2, -3.4] 
true_b &#x3D; 4.2 
features &#x3D; torch.randn(num_examples, num_inputs, dtype&#x3D;torch.float32) 
labels &#x3D; true_w[0] * features[:, 0] + true_w[1] * features[:,1]+true_b
labels +&#x3D; torch.tensor(np.random.normal(0, 0.01, size&#x3D;labels.size()), dtype&#x3D;torch.float32)

features[0], labels[0]ã€

from IPython import display


def use_svg_display():
    display.set_matplotlib_formats(&#39;svg&#39;)

def set_figsize(figsize&#x3D;(3.5,2.5)):
    use_svg_display()
    plt.rcParams[&#39;figure.figsize&#39;] &#x3D; figsize

set_figsize()

plt.scatter(features[:, 1].numpy(), labels.numpy(), 1)

# å½¢æˆä¸€ä¸ªbatch
def data_iter(batch_size, features, labels):
    num_examples &#x3D; len(features)
    indices&#x3D;list(range(num_examples))
    # æ ·æœ¬è¯»å–é¡ºåºéšæœº, ç´¢å¼•
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        # æœ€åä¸€æ¬¡å¯èƒ½ä¸å¤Ÿä¸€ä¸ªbatch
        j &#x3D; torch.LongTensor(indices[i : min(i+batch_size, num_examples)])

        yield features.index_select(0, j), labels.index_select(0, j)

# ä¸€ä¸ªbatch
batch_size &#x3D; 10
for X, y in data_iter(batch_size, features, labels):
    print (X ,y)
    break
# X æ˜¯ä¸€ä¸ªbatchçš„æ•°æ®, batchsize*2çš„çŸ©é˜µ
# w æ˜¯2*1çš„tensor
def linreg(X, w, b):
    return torch.mm(X, w) + b

def square_loss(y_hat, y):
    return (y_hat - y.view(y_hat.size()))**2
# ä¼˜åŒ–ç®—æ³•
def sgd(params, lr, batch_size):
    for param in params:
        # è‡ªåŠ¨æ±‚æ¢¯åº¦æ¨¡å—æ˜¯æ‰¹é‡æ ·æœ¬çš„æ¢¯åº¦å’Œï¼Œé™¤ä»¥batchå¤§å°ä½œä¸ºbatchæ¢¯åº¦å¹³å‡å€¼
        param.data -&#x3D; lr*param.grad &#x2F; batch_size

# åˆå§‹åŒ–å‚æ•°
w &#x3D; torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype&#x3D;torch.float32)
b &#x3D; torch.zeros(1, dtype&#x3D;torch.float32)

w.requires_grad_(requires_grad &#x3D; True)
b.requires_grad_(requires_grad&#x3D;True)


lr &#x3D; 0.03
num_epochs &#x3D; 3
net &#x3D; linreg
loss &#x3D; square_loss

for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        # å…³äºX, yçš„æŸå¤±ã€‚ä¸€æ¬¡æ±‚ä¸€ä¸ªbatch_size
        # lossè¿”å›batchsizeçš„è¡Œå‘é‡ï¼ŒåŠ ä¸ªsumæ˜¯æŸå¤±å’Œ
        l &#x3D; loss(net(X, w, b), y).sum()
        l.backward() # å‚æ•°æ±‚æ¢¯åº¦
        sgd([w, b], lr, batch_size)

        # æ¢¯åº¦æ¸…é›¶
        w.grad.data.zero_()
        b.grad.data.zero_()
    train_l &#x3D; loss(net(features, w, b), labels)
    print (&#39;epoch %d, loss %f&#39; % (epoch+1, train_l.mean().item()))
</code></pre>

<p>æ¨¡å—å‹å†™æ³•</p>
<pre class="language-py" data-language="py"><code class="language-py">num_inputs &#x3D; 2
num_examples &#x3D; 1000
true_w &#x3D; [2, -3.4]
true_b &#x3D; 4.2

features &#x3D; torch.tensor(
    np.random.normal(0, 1, (num_examples, num_inputs)),
    dtype &#x3D; torch.float32
)
labels &#x3D; true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b
labels +&#x3D; torch.tensor(np.random.normal(0, 0.01, size&#x3D;labels.size()), dtype&#x3D;torch.float32)


import torch.utils.data as Data

batch_size &#x3D; 10
# ç‰¹å¾æ ‡ç­¾ç»„åˆ
dataset &#x3D; Data.TensorDataset(features, labels)
# éšæœºé€‰å–å°æ‰¹é‡
data_iter &#x3D; Data.DataLoader(dataset, batch_size, shuffle&#x3D;True)

from torch import nn 
class LinearNet(nn.Module):
    def __init__(self, n_feature):
        super(LinearNet, self).__init__()
        self.linear &#x3D; nn.Linear(n_feature, 1)

    def forward(self, x):
        y &#x3D; self.linear(x)
        return y
net &#x3D; LinearNet(num_inputs)

print (net)


net2 &#x3D; nn.Sequential()
net2.add_module(&#39;linear&#39;, nn.Linear(num_inputs, 1))

# net.parameters()å¯æŸ¥çœ‹æ¨¡å‹æ‰€æœ‰å¯å­¦ä¹ å‚æ•°ï¼Œå‡½æ•°è¿”å›ä¸€ä¸ªç”Ÿæˆå™¨
for param in net.parameters():
    print (param)

# åˆå§‹åŒ–æ¨¡å‹å‚æ•°
from torch.nn import init

init.normal_(net.linear.weight, mean&#x3D;0, std&#x3D;0.01)
init.constant_(net.linear.bias, val&#x3D;0)

loss &#x3D; nn.MSELoss()

import torch.optim as optim

optimizer &#x3D; optim.SGD(net.parameters(), lr&#x3D;0.03)
print (optimizer)

num_epoch &#x3D; 3
for epoch in range(1, num_epochs+1):
    for X, y in data_iter:
        output &#x3D; net(X)
        l &#x3D; loss(output, y.view(-1, 1))
        # æ¢¯åº¦æ¸…é›¶
        optimizer.zero_grad()
        # åå‘ä¼ æ’­å¾—åˆ°æ¢¯åº¦
        l.backward()
        # æ›´æ–°å‚æ•°
        optimizer.step()
    print (&#39;epoch %d, loss %f&#39; % (epoch+1, train_l.mean().item()))</code></pre>
<p>å…¶ä¸­<code>nn.Sequential</code>å¯ç”¨çœ‹ä½œæœ‰åºå®¹å™¨ï¼Œç½‘ç»œå±‚å°†æ ¹æ®ä¼ å…¥<code>Sequential</code>çš„é¡ºåºä¾æ¬¡æ·»åŠ å…¥ç½‘ç»œå±‚ä¸­ï¼Œç»™å®šè¾“å…¥æ•°æ®æ—¶ï¼Œå®¹å™¨æŸä¸€å±‚å°†ä¾æ¬¡è®¡ç®—å¹¶è¾“å‡ºä½œä¸ºä¸‹ä¸€å±‚è¾“å…¥ã€‚</p>
<h4 id="softmaxæ¨¡å‹"><a href="#softmaxæ¨¡å‹" class="headerlink" title="softmaxæ¨¡å‹"></a>softmaxæ¨¡å‹</h4><p>softmaxå›å½’å’Œçº¿æ€§å›å½’ä¸€æ ·å°†è¾“å…¥ç‰¹å¾ä¸æƒé‡åšçº¿æ€§ç´¯åŠ ï¼Œä½†ä¸åŒä¹‹å¤„æ˜¯è¾“å‡ºå€¼ä¸ªæ•°ç­‰äºæ ‡ç­¾é‡Œçš„ç±»åˆ«æ•°ã€‚ä¹Ÿå«åšå…¨è¿æ¥å±‚ã€‚</p>
<p>softmaxè¿ç®—å°†è¾“å‡ºå€¼å˜æˆæ­£ä¸”å’Œä¸º1çš„æ¦‚ç‡åˆ†å¸ƒã€‚</p>
<h4 id="ç»§æ‰¿Muduleç±»æ¥æ„é€ æ¨¡å‹"><a href="#ç»§æ‰¿Muduleç±»æ¥æ„é€ æ¨¡å‹" class="headerlink" title="ç»§æ‰¿Muduleç±»æ¥æ„é€ æ¨¡å‹"></a>ç»§æ‰¿Muduleç±»æ¥æ„é€ æ¨¡å‹</h4><p>Moduleç±»æ˜¯nnæ¨¡å—æä¾›çš„æ¨¡å‹æ„é€ ç±»ï¼Œæ˜¯æ‰€æœ‰ç¥ç»ç½‘ç»œæ¨¡å—çš„åŸºç±»</p>
<pre class="language-py" data-language="py"><code class="language-py">import torch
from torch import nn
class MLP(nn.Module):
    def __init__(self, **kwargs):
        super(MLP, self).__init__(**kwargs)

        self.hidden &#x3D; nn.Linear(784, 256)
        self.act &#x3D; nn.Relu()
        self.output &#x3D; nn.Linear(256,10)
    def forward(self, x):
        a &#x3D; self.act(self.hidden(x))
        return self.output(a)

x &#x3D; torch.randn(2, 784)
net &#x3D; MLP()
print (net)
net(x)</code></pre>
<p><code>net(x)</code>ä¼šè°ƒç”¨MLPç»§æ‰¿è‡ªMuduleç±»çš„<code>__call__</code>å‡½æ•°ï¼Œè¯¥å‡½æ•°è°ƒç”¨MLPå®šä¹‰çš„forwardå‡½æ•°æ¥å®Œæˆå‰å‘è®¡ç®—ã€‚</p>
<h4 id="GPUè®¡ç®—"><a href="#GPUè®¡ç®—" class="headerlink" title="GPUè®¡ç®—"></a>GPUè®¡ç®—</h4><pre class="language-py" data-language="py"><code class="language-py">a &#x3D; torch.tensor([1,2,3], device &#x3D; torch.device(&#39;cuda:1&#39;))

import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] &#x3D; &quot;2&quot;

device &#x3D; torch.device(
    &#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;
)

cuda_gpu &#x3D; torch.cuda.is_available()
if(cuda_gpu):
    net &#x3D; torch.nn.DataParallel(net).cuda()</code></pre>
<p>æ³¨æ„å­˜å‚¨åœ¨ä¸åŒä½ç½®çš„æ•°æ®ä¸èƒ½ç›´æ¥è®¡ç®—ï¼Œä¸åŒGPUçš„æ•°æ®ä¹Ÿä¸èƒ½ç›´æ¥è®¡ç®—ã€‚pytorchè¦æ±‚æ‰€æœ‰è¾“å…¥æ•°æ®éƒ½åœ¨å†…å­˜æˆ–è€…åŒä¸€å—æ˜¾å¡çš„æ˜¾å­˜ä¸Šã€‚ device=â€™cpuâ€™è¯´æ˜Tensorå­˜å‚¨åœ¨å†…å­˜ä¸Šã€‚</p>
<h4 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h4><pre class="language-py" data-language="py"><code class="language-py">import time
import math
import numpy as np
import torch
from torch import nn, optim
import torch.nn.functional as F

import sys
sys.path.append(&quot;..&quot;) 
import d2lzh_pytorch as d2l
device &#x3D; torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)

print(torch.__version__)
print(device)

(corpus_indices, char_to_idx, idx_to_char, vocab_size) &#x3D; d2l.load_data_jay_lyrics()

# one-hotç¼–ç 
def one_hot(x, n_class, dtype&#x3D;torch.float32): 
    # X shape: (batch), output shape: (batch, n_class)
    x &#x3D; x.long()
    res &#x3D; torch.zeros(x.shape[0], n_class, dtype&#x3D;dtype, device&#x3D;x.device)
    # scatter_(dim, index, src)
    # dim æ”¹æ•°æ®çš„ç»´åº¦ï¼Œ ç´¢å¼•ï¼Œ æ›¿æ¢å€¼
    res.scatter_(1, x.view(-1, 1), 1)
    return res
    
x &#x3D; torch.tensor([0, 2])
one_hot(x, vocab_size)

def to_onehot(X, n_class):  
    # X shape: (batch, seq_len), output: seq_len elements of (batch, n_class)
    return [one_hot(X[:, i], n_class) for i in range(X.shape[1])]

X &#x3D; torch.arange(10).view(2, 5)
inputs &#x3D; to_onehot(X, vocab_size)
print(len(inputs), inputs[0].shape)
# è¾“å‡º
5 torch.Size([2, 1027]) torch.Size([2, 256])

# 2*5 -&gt; 5*2*256
# å°ºå¯¸å˜åŒ– batch_size * seq_len -&gt;  seq_len * batch * vocab_size
# num_inputs &#x3D; vocab_size

num_inputs, num_hiddens, num_outputs &#x3D; vocab_size, 256, vocab_size
print(&#39;will use&#39;, device)

def get_params():
    def _one(shape):
        ts &#x3D; torch.tensor(np.random.normal(0, 0.01, size&#x3D;shape), device&#x3D;device, dtype&#x3D;torch.float32)
        return torch.nn.Parameter(ts, requires_grad&#x3D;True)

    # éšè—å±‚å‚æ•°
    W_xh &#x3D; _one((num_inputs, num_hiddens))
    W_hh &#x3D; _one((num_hiddens, num_hiddens))
    b_h &#x3D; torch.nn.Parameter(torch.zeros(num_hiddens, device&#x3D;device, requires_grad&#x3D;True))
    # è¾“å‡ºå±‚å‚æ•°
    W_hq &#x3D; _one((num_hiddens, num_outputs))
    b_q &#x3D; torch.nn.Parameter(torch.zeros(num_outputs, device&#x3D;device, requires_grad&#x3D;True))
    return nn.ParameterList([W_xh, W_hh, b_h, W_hq, b_q])

# åˆå§‹åŒ–
def init_rnn_state(batch_size, num_hiddens, device):
    return (torch.zeros((batch_size, num_hiddens), device&#x3D;device))

def rnn(inputs, state, params):
    # inputså’Œoutputsçš†ä¸ºnum_stepsä¸ªå½¢çŠ¶ä¸º(batch_size, vocab_size)çš„çŸ©é˜µï¼Œ å‚æ•°
    W_xh, W_hh, b_h, W_hq, b_q &#x3D; params
    H, &#x3D; state
    outputs &#x3D; []
    for X in inputs:
        # å¤„ç†æ¯ä¸€ä¸ªseqå­—ç¬¦
        # batch_size * hidden_size
        H &#x3D; torch.tanh(torch.matmul(X, W_xh) + torch.matmul(H, W_hh) + b_h)
        Y &#x3D; torch.matmul(H, W_hq) + b_q
        outputs.append(Y)
    # seq_len * batch_size * num_outputs(vocab_size)
    return outputs, (H,)

# batch_size * hidden_size
# input seq_len * batch * vocab_size
state &#x3D; init_rnn_state(X.shape[0], num_hiddens, device)
inputs &#x3D; to_onehot(X.to(device), vocab_size)
params &#x3D; get_params()
outputs, state_new &#x3D; rnn(inputs, state, params)
print(len(outputs), outputs[0].shape, state_new[0].shape)

# è¾“å‡º
5 torch.Size([2, 1027]) torch.Size([2, 256])

# è£å‰ªæ¢¯åº¦
def grad_clipping(params, theta, device):
    norm &#x3D; torch.tensor([0.0], device&#x3D;device)
    for param in params:
        norm +&#x3D; (param.grad.data ** 2).sum()
    norm &#x3D; norm.sqrt().item()
    if norm &gt; theta:
        for param in params:
            param.grad.data *&#x3D; (theta &#x2F; norm)
# é¢„æµ‹
def predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,
                num_hiddens, vocab_size, device, idx_to_char, char_to_idx):
    state &#x3D; init_rnn_state(1, num_hiddens, device)
    output &#x3D; [char_to_idx[prefix[0]]]
    for t in range(num_chars + len(prefix) - 1):
        # å°†ä¸Šä¸€æ—¶é—´æ­¥çš„è¾“å‡ºä½œä¸ºå½“å‰æ—¶é—´æ­¥çš„è¾“å…¥
        X &#x3D; to_onehot(torch.tensor([[output[-1]]], device&#x3D;device), vocab_size)
        # è®¡ç®—è¾“å‡ºå’Œæ›´æ–°éšè—çŠ¶æ€
        (Y, state) &#x3D; rnn(X, state, params)
        # ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥æ˜¯prefixé‡Œçš„å­—ç¬¦æˆ–è€…å½“å‰çš„æœ€ä½³é¢„æµ‹å­—ç¬¦
        if t &lt; len(prefix) - 1:
            output.append(char_to_idx[prefix[t + 1]])
        else:
            output.append(int(Y[0].argmax(dim&#x3D;1).item()))
    return &#39;&#39;.join([idx_to_char[i] for i in output])

predict_rnn(&#39;åˆ†å¼€&#39;, 10, rnn, params, init_rnn_state, num_hiddens, vocab_size,device, idx_to_char, char_to_idx)

&#39;åˆ†å¼€å…»è¿‘æœ‹èº«å€’çˆ½æŠ±ç–‘æ£’é‚»&#39;

def train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,
                          vocab_size, device, corpus_indices, idx_to_char,
                          char_to_idx, is_random_iter, num_epochs, num_steps,
                          lr, clipping_theta, batch_size, pred_period,
                          pred_len, prefixes):
    if is_random_iter:
        data_iter_fn &#x3D; d2l.data_iter_random
    else:
        data_iter_fn &#x3D; d2l.data_iter_consecutive
    params &#x3D; get_params()
    loss &#x3D; nn.CrossEntropyLoss()

    for epoch in range(num_epochs):
        if not is_random_iter:  # å¦‚ä½¿ç”¨ç›¸é‚»é‡‡æ ·ï¼Œåœ¨epochå¼€å§‹æ—¶åˆå§‹åŒ–éšè—çŠ¶æ€
            state &#x3D; init_rnn_state(batch_size, num_hiddens, device)
        l_sum, n, start &#x3D; 0.0, 0, time.time()
        data_iter &#x3D; data_iter_fn(corpus_indices, batch_size, num_steps, device)
        for X, Y in data_iter:
            if is_random_iter:  # å¦‚ä½¿ç”¨éšæœºé‡‡æ ·ï¼Œåœ¨æ¯ä¸ªå°æ‰¹é‡æ›´æ–°å‰åˆå§‹åŒ–éšè—çŠ¶æ€
                state &#x3D; init_rnn_state(batch_size, num_hiddens, device)
            else:  # å¦åˆ™éœ€è¦ä½¿ç”¨detachå‡½æ•°ä»è®¡ç®—å›¾åˆ†ç¦»éšè—çŠ¶æ€
                for s in state:
                    s.detach_()
            inputs &#x3D; to_onehot(X, vocab_size)
            # outputsæœ‰num_stepsä¸ªå½¢çŠ¶ä¸º(batch_size, vocab_size)çš„çŸ©é˜µ
            (outputs, state) &#x3D; rnn(inputs, state, params)
            # æ‹¼æ¥ä¹‹åå½¢çŠ¶ä¸º(num_steps * batch_size, vocab_size)
            outputs &#x3D; torch.cat(outputs, dim&#x3D;0)
            # Yçš„å½¢çŠ¶æ˜¯(batch_size, num_steps)ï¼Œè½¬ç½®åå†å˜æˆé•¿åº¦ä¸º
            # batch * num_steps çš„å‘é‡ï¼Œè¿™æ ·è·Ÿè¾“å‡ºçš„è¡Œä¸€ä¸€å¯¹åº”
            y &#x3D; torch.transpose(Y, 0, 1).contiguous().view(-1)
            # ä½¿ç”¨äº¤å‰ç†µæŸå¤±è®¡ç®—å¹³å‡åˆ†ç±»è¯¯å·®
            l &#x3D; loss(outputs, y.long())
            
            # æ¢¯åº¦æ¸…0
            if params[0].grad is not None:
                for param in params:
                    param.grad.data.zero_()
            l.backward()
            grad_clipping(params, clipping_theta, device)  # è£å‰ªæ¢¯åº¦
            d2l.sgd(params, lr, 1)  # å› ä¸ºè¯¯å·®å·²ç»å–è¿‡å‡å€¼ï¼Œæ¢¯åº¦ä¸ç”¨å†åšå¹³å‡
            l_sum +&#x3D; l.item() * y.shape[0]
            n +&#x3D; y.shape[0]

        if (epoch + 1) % pred_period &#x3D;&#x3D; 0:
            print(&#39;epoch %d, perplexity %f, time %.2f sec&#39; % (
                epoch + 1, math.exp(l_sum &#x2F; n), time.time() - start))
            for prefix in prefixes:
                print(&#39; -&#39;, predict_rnn(prefix, pred_len, rnn, params, init_rnn_state,
                    num_hiddens, vocab_size, device, idx_to_char, char_to_idx))</code></pre>

<h4 id="æ³¨æ„åŠ›æœºåˆ¶"><a href="#æ³¨æ„åŠ›æœºåˆ¶" class="headerlink" title="æ³¨æ„åŠ›æœºåˆ¶"></a>æ³¨æ„åŠ›æœºåˆ¶</h4><pre class="language-py" data-language="py"><code class="language-py">def attention_model(input_size, attention_size):
    model &#x3D; nn.Sequential(nn.Linear(input_size, attention_size, bias&#x3D;False),
                          nn.Tanh(),
                          nn.Linear(attention_size, 1, bias&#x3D;False))
    return model

def attention_forward(model, enc_states, dec_state):
    &quot;&quot;&quot;
    enc_states: (æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, éšè—å•å…ƒä¸ªæ•°)
    dec_state: (æ‰¹é‡å¤§å°, éšè—å•å…ƒä¸ªæ•°)
    &quot;&quot;&quot;
    # å°†è§£ç å™¨éšè—çŠ¶æ€å¹¿æ’­åˆ°å’Œç¼–ç å™¨éšè—çŠ¶æ€å½¢çŠ¶ç›¸åŒåè¿›è¡Œè¿ç»“
    dec_states &#x3D; dec_state.unsqueeze(dim&#x3D;0).expand_as(enc_states)
    enc_and_dec_states &#x3D; torch.cat((enc_states, dec_states), dim&#x3D;2)
    # è¾“å…¥è¿æ¥åé€šå…¥å¤šå±‚æ„ŸçŸ¥æœº
    e &#x3D; model(enc_and_dec_states)  # å½¢çŠ¶ä¸º(æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, 1)
    alpha &#x3D; F.softmax(e, dim&#x3D;0)  # åœ¨æ—¶é—´æ­¥ç»´åº¦åšsoftmaxè¿ç®—ï¼Œç»“æœä»ä¸º(æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, 1) 

    # å¯¹enc_statesçš„åŠ æƒæ±‚å’Œ
    return (alpha * enc_states).sum(dim&#x3D;0)  # è¿”å›èƒŒæ™¯å˜é‡

seq_len, batch_size, num_hiddens &#x3D; 10, 4, 8
model &#x3D; attention_model(2*num_hiddens, 10) 
# (æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, éšè—å•å…ƒä¸ªæ•°)
enc_states &#x3D; torch.zeros((seq_len, batch_size, num_hiddens))
dec_state &#x3D; torch.zeros((batch_size, num_hiddens))
attention_forward(model, enc_states, dec_state).shape

torch.Size([4, 8])

</code></pre>

<h4 id="ç¼–ç å™¨å’Œè§£ç å™¨"><a href="#ç¼–ç å™¨å’Œè§£ç å™¨" class="headerlink" title="ç¼–ç å™¨å’Œè§£ç å™¨"></a>ç¼–ç å™¨å’Œè§£ç å™¨</h4><pre class="language-py" data-language="py"><code class="language-py">#ä¸‰ç§ç‰¹æ®Šå­—ç¬¦
PAD, BOS, EOS &#x3D; &#39;&lt;pad&gt;&#39;, &#39;&lt;bos&gt;&#39;, &#39;&lt;eos&gt;&#39;
# å°†ä¸€ä¸ªåºåˆ—ä¸­æ‰€æœ‰çš„è¯è®°å½•åœ¨all_tokensä¸­ä»¥ä¾¿ä¹‹åæ„é€ è¯å…¸ï¼Œç„¶ååœ¨è¯¥åºåˆ—åé¢æ·»åŠ PADç›´åˆ°åºåˆ—
# é•¿åº¦å˜ä¸ºmax_seq_lenï¼Œç„¶åå°†åºåˆ—ä¿å­˜åœ¨all_seqsä¸­
def process_one_seq(seq_tokens, all_tokens, all_seqs, max_seq_len):
    all_tokens.extend(seq_tokens)
    seq_tokens +&#x3D; [EOS] + [PAD] * (max_seq_len - len(seq_tokens) - 1)
    all_seqs.append(seq_tokens)

# ä½¿ç”¨æ‰€æœ‰çš„è¯æ¥æ„é€ è¯å…¸ã€‚å¹¶å°†æ‰€æœ‰åºåˆ—ä¸­çš„è¯å˜æ¢ä¸ºè¯ç´¢å¼•åæ„é€ Tensor
def build_data(all_tokens, all_seqs):
    vocab &#x3D; Vocab.Vocab(collections.Counter(all_tokens),
                        specials&#x3D;[PAD, BOS, EOS])
    indices &#x3D; [[vocab.stoi[w] for w in seq] for seq in all_seqs]
    return vocab, torch.tensor(indices)

def read_data(max_seq_len):
    # inå’Œoutåˆ†åˆ«æ˜¯inputå’Œoutputçš„ç¼©å†™
    in_tokens, out_tokens, in_seqs, out_seqs &#x3D; [], [], [], []
    with io.open(&#39;..&#x2F;..&#x2F;data&#x2F;fr-en-small.txt&#39;) as f:
        lines &#x3D; f.readlines()
    for line in lines:
        in_seq, out_seq &#x3D; line.rstrip().split(&#39;\t&#39;)
        in_seq_tokens, out_seq_tokens &#x3D; in_seq.split(&#39; &#39;), out_seq.split(&#39; &#39;)
        if max(len(in_seq_tokens), len(out_seq_tokens)) &gt; max_seq_len - 1:
            continue  # å¦‚æœåŠ ä¸ŠEOSåé•¿äºmax_seq_lenï¼Œåˆ™å¿½ç•¥æ‰æ­¤æ ·æœ¬
        process_one_seq(in_seq_tokens, in_tokens, in_seqs, max_seq_len)
        process_one_seq(out_seq_tokens, out_tokens, out_seqs, max_seq_len)
    in_vocab, in_data &#x3D; build_data(in_tokens, in_seqs)
    out_vocab, out_data &#x3D; build_data(out_tokens, out_seqs)
    return in_vocab, out_vocab, Data.TensorDataset(in_data, out_data)

class Encoder(nn.Module):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 drop_prob&#x3D;0, **kwargs):
        super(Encoder, self).__init__(**kwargs)
        self.embedding &#x3D; nn.Embedding(vocab_size, embed_size)
        self.rnn &#x3D; nn.GRU(embed_size, num_hiddens, num_layers, dropout&#x3D;drop_prob)

    def forward(self, inputs, state):
        # è¾“å…¥å½¢çŠ¶æ˜¯(æ‰¹é‡å¤§å°, æ—¶é—´æ­¥æ•°)ã€‚å°†è¾“å‡ºäº’æ¢æ ·æœ¬ç»´å’Œæ—¶é—´æ­¥ç»´
        embedding &#x3D; self.embedding(inputs.long()).permute(1, 0, 2) # (seq_len, batch, input_size)
        return self.rnn(embedding, state)

    def begin_state(self):
        return None
encoder &#x3D; Encoder(vocab_size&#x3D;10, embed_size&#x3D;8, num_hiddens&#x3D;16, num_layers&#x3D;2)
output, state &#x3D; encoder(torch.zeros((4, 7)), encoder.begin_state())
output.shape, state.shape # GRUçš„stateæ˜¯h, è€ŒLSTMçš„æ˜¯ä¸€ä¸ªå…ƒç»„(h, c)

(torch.Size([7, 4, 16]), torch.Size([2, 4, 16]))


# è§£ç å™¨
class Decoder(nn.Module):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 attention_size, drop_prob&#x3D;0):
        super(Decoder, self).__init__()
        self.embedding &#x3D; nn.Embedding(vocab_size, embed_size)
        self.attention &#x3D; attention_model(2*num_hiddens, attention_size)
        # GRUçš„è¾“å…¥åŒ…å«attentionè¾“å‡ºçš„cå’Œå®é™…è¾“å…¥, æ‰€ä»¥å°ºå¯¸æ˜¯ num_hiddens+embed_size
        self.rnn &#x3D; nn.GRU(num_hiddens + embed_size, num_hiddens, 
                          num_layers, dropout&#x3D;drop_prob)
        self.out &#x3D; nn.Linear(num_hiddens, vocab_size)

    def forward(self, cur_input, state, enc_states):
        &quot;&quot;&quot;
        cur_input shape: (batch, )
        state shape: (num_layers, batch, num_hiddens)
        &quot;&quot;&quot;
        # ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—èƒŒæ™¯å‘é‡
        c &#x3D; attention_forward(self.attention, enc_states, state[-1])
        # å°†åµŒå…¥åçš„è¾“å…¥å’ŒèƒŒæ™¯å‘é‡åœ¨ç‰¹å¾ç»´è¿ç»“, (æ‰¹é‡å¤§å°, num_hiddens+embed_size)
        input_and_c &#x3D; torch.cat((self.embedding(cur_input), c), dim&#x3D;1) 
        # ä¸ºè¾“å…¥å’ŒèƒŒæ™¯å‘é‡çš„è¿ç»“å¢åŠ æ—¶é—´æ­¥ç»´ï¼Œæ—¶é—´æ­¥ä¸ªæ•°ä¸º1
        output, state &#x3D; self.rnn(input_and_c.unsqueeze(0), state)
        # ç§»é™¤æ—¶é—´æ­¥ç»´ï¼Œè¾“å‡ºå½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°, è¾“å‡ºè¯å…¸å¤§å°)
        output &#x3D; self.out(output).squeeze(dim&#x3D;0)
        return output, state

    def begin_state(self, enc_state):
        # ç›´æ¥å°†ç¼–ç å™¨æœ€ç»ˆæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ä½œä¸ºè§£ç å™¨çš„åˆå§‹éšè—çŠ¶æ€
        return enc_state

def batch_loss(encoder, decoder, X, Y, loss):
    # (1) ç¼–ç å¾—åˆ°å‘é‡c
    # (2) åŸºäºå‘é‡cç­‰è§£ç ä¸€é
    # (3) æ±‚æŸå¤±å‡½æ•°ï¼Œæ›´æ–°å‚æ•°
    batch_size &#x3D; X.shape[0]
    enc_state &#x3D; encoder.begin_state()
    # ç¼–ç å™¨ï¼ŒåŒæ—¶æ›´æ–°å½“å‰ç¼–ç çŠ¶æ€
    enc_outputs, enc_state &#x3D; encoder(X, enc_state)
    # åˆå§‹åŒ–è§£ç å™¨çš„éšè—çŠ¶æ€
    dec_state &#x3D; decoder.begin_state(enc_state)
    # è§£ç å™¨åœ¨æœ€åˆæ—¶é—´æ­¥çš„è¾“å…¥æ˜¯BOS
    dec_input &#x3D; torch.tensor([out_vocab.stoi[BOS]] * batch_size)
    # æˆ‘ä»¬å°†ä½¿ç”¨æ©ç å˜é‡maskæ¥å¿½ç•¥æ‰æ ‡ç­¾ä¸ºå¡«å……é¡¹PADçš„æŸå¤±, åˆå§‹å…¨1
    # æ³¨æ„ä¸€æ¬¡æ€§å¤„ç†çš„æ˜¯ä¸€ä¸ªbatchsize
    mask, num_not_pad_tokens &#x3D; torch.ones(batch_size,), 0
    l &#x3D; torch.tensor([0.0])
    for y in Y.permute(1,0): #ç»´åº¦æ¢ä½ã€‚ Y shape: (batch, seq_len)
    # åŸºäºå½“å‰yå­—ç¬¦ï¼ŒçŠ¶æ€ï¼Œenc_outputså¯¹yè¿›è¡Œè§£ç 
    # åŒæ—¶æ›´æ–°å½“å‰è§£ç è¾“å…¥å’Œè§£ç çŠ¶æ€
        dec_output, dec_state &#x3D; decoder(dec_input, dec_state, enc_outputs)
        l &#x3D; l + (mask * loss(dec_output, y)).sum()
        dec_input &#x3D; y  # ä½¿ç”¨å¼ºåˆ¶æ•™å­¦

        num_not_pad_tokens +&#x3D; mask.sum().item()
        # EOSåé¢å…¨æ˜¯PAD. ä¸‹é¢ä¸€è¡Œä¿è¯ä¸€æ—¦é‡åˆ°EOSæ¥ä¸‹æ¥çš„å¾ªç¯ä¸­maskå°±ä¸€ç›´æ˜¯0
        # ä¸€æ—¦é‡åˆ°EOSåœæ­¢è§£ç 
        mask &#x3D; mask * (y !&#x3D; out_vocab.stoi[EOS]).float()
    # æŸå¤±å‡½æ•°ï¼Œåˆ†æ¯æ˜¯épaddingçš„å­—ç¬¦æ•°é‡
    return l &#x2F; num_not_pad_tokens

def train(encoder, decoder, dataset, lr, batch_size, num_epochs):
    enc_optimizer &#x3D; torch.optim.Adam(encoder.parameters(), lr&#x3D;lr)
    dec_optimizer &#x3D; torch.optim.Adam(decoder.parameters(), lr&#x3D;lr)

    loss &#x3D; nn.CrossEntropyLoss(reduction&#x3D;&#39;none&#39;)
    data_iter &#x3D; Data.DataLoader(dataset, batch_size, shuffle&#x3D;True)
    for epoch in range(num_epochs):
        l_sum &#x3D; 0.0
        for X, Y in data_iter:
            enc_optimizer.zero_grad()
            dec_optimizer.zero_grad()
            l &#x3D; batch_loss(encoder, decoder, X, Y, loss)
            l.backward()
            enc_optimizer.step()
            dec_optimizer.step()
            l_sum +&#x3D; l.item()
        if (epoch + 1) % 10 &#x3D;&#x3D; 0:
            print(&quot;epoch %d, loss %.3f&quot; % (epoch + 1, l_sum &#x2F; len(data_iter)))

embed_size, num_hiddens, num_layers &#x3D; 64, 64, 2
attention_size, drop_prob, lr, batch_size, num_epochs &#x3D; 10, 0.5, 0.01, 2, 50
encoder &#x3D; Encoder(len(in_vocab), embed_size, num_hiddens, num_layers,
                  drop_prob)
decoder &#x3D; Decoder(len(out_vocab), embed_size, num_hiddens, num_layers,
                  attention_size, drop_prob)
train(encoder, decoder, dataset, lr, batch_size, num_epochs)


# é¢„æµ‹
def translate(encoder, decoder, input_seq, max_seq_len):
    in_tokens &#x3D; input_seq.split(&#39; &#39;)
    in_tokens +&#x3D; [EOS] + [PAD] * (max_seq_len - len(in_tokens) - 1)
    enc_input &#x3D; torch.tensor([[in_vocab.stoi[tk] for tk in in_tokens]]) # batch&#x3D;1
    enc_state &#x3D; encoder.begin_state()
    # ç¼–ç ï¼ŒåŸºäºè®­ç»ƒå¥½çš„å‚æ•°
    enc_output, enc_state &#x3D; encoder(enc_input, enc_state)
    # èµ·å§‹å•è¯BOS
    dec_input &#x3D; torch.tensor([out_vocab.stoi[BOS]])
    dec_state &#x3D; decoder.begin_state(enc_state)
    output_tokens &#x3D; []

    # è§£ç ï¼Œè·å–é¢„æµ‹çš„åºåˆ—
    for _ in range(max_seq_len):
        dec_output, dec_state &#x3D; decoder(dec_input, dec_state, enc_output)
        pred &#x3D; dec_output.argmax(dim&#x3D;1)

        pred_token &#x3D; out_vocab.itos[int(pred.item())]
        if pred_token &#x3D;&#x3D; EOS:  # å½“ä»»ä¸€æ—¶é—´æ­¥æœç´¢å‡ºEOSæ—¶ï¼Œè¾“å‡ºåºåˆ—å³å®Œæˆ
            break
        else:
            output_tokens.append(pred_token)
            dec_input &#x3D; pred
    return output_tokens

input_seq &#x3D; &#39;ils regardent .&#39;
translate(encoder, decoder, input_seq, max_seq_len)

[&#39;they&#39;, &#39;are&#39;, &#39;watching&#39;, &#39;.&#39;]</code></pre></div></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/2021-07-17-NLP%E4%B8%80%E4%BA%9B%E5%B7%A5%E5%85%B7/" rel="prev" title="NLP tools"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">NLP tools</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/2021-07-14-python%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%89%8B%E5%86%8C/" rel="next" title="pythonæ•°æ®åˆ†æ"><span class="post-nav-text">pythonæ•°æ®åˆ†æ</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>å¦‚æœæ‚¨æœ‰ä»»ä½•å…³äºåšå®¢å†…å®¹çš„ç›¸å…³è®¨è®ºï¼Œæ¬¢è¿å‰å¾€ <a href="https://github.com/YunYouJun/yunyoujun.github.io/discussions" target="_blank">GitHub Discussions</a> ä¸æˆ‘äº¤æµã€‚</span><br></div><div id="valine-container"></div><script>Yun.utils.getScript("https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js", () => {
  const valineConfig = {"enable":true,"appId":"K4LElSwpTJaHOOTTU6mNGCyr-gzGzoHsz","appKey":"x3d4Sv6rdTYOECKqkxg9r905","placeholder":"å¡«å†™é‚®ç®±ï¼Œå¯ä»¥æ”¶åˆ°å›å¤é€šçŸ¥å“¦ï½","avatar":null,"pageSize":10,"visitor":false,"highlight":true,"recordIP":false,"enableQQ":true,"meta":["nick","mail","link"],"el":"#valine-container","lang":"zh-cn"}
  valineConfig.path = "/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/2021-07-15-pytorch%E5%92%8Ctensorflow/"
  new Valine(valineConfig)
}, window.Valine);</script></div></main><footer class="sidebar-translate" id="footer"><div class="beian"><a rel="noopener" href="https://beian.miit.gov.cn/" target="_blank">èŒICPå¤‡666666å·</a></div><div class="copyright"><span>&copy; 2020 â€“ 2021 </span><a class="with-love" id="animate" target="_blank" rel="noopener" href="https://sponsors.yunyoujun.cn" title="äº‘æ¸¸å›çš„èµåŠ©è€…ä»¬"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></a><span class="author"> larry</span></div><div class="powered"><span>ç”± <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> é©±åŠ¨ v5.4.0</span><span class="footer-separator">|</span><span>ä¸»é¢˜ - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.6.3</span></div><div class="live_time"><span>æœ¬åšå®¢å·²èŒèŒå“’åœ°è¿è¡Œ</span><span id="display_live_time"></span><span class="moe-text">(â—'â—¡'â—)</span><script>function blog_live_time() {
  setTimeout(blog_live_time, 1000);
  const start = new Date('2020-04-12T00:00:00');
  const now = new Date();
  const timeDiff = (now.getTime() - start.getTime());
  const msPerMinute = 60 * 1000;
  const msPerHour = 60 * msPerMinute;
  const msPerDay = 24 * msPerHour;
  const passDay = Math.floor(timeDiff / msPerDay);
  const passHour = Math.floor((timeDiff % msPerDay) / 60 / 60 / 1000);
  const passMinute = Math.floor((timeDiff % msPerHour) / 60 / 1000);
  const passSecond = Math.floor((timeDiff % msPerMinute) / 1000);
  display_live_time.innerHTML = " " + passDay + " å¤© " + passHour + " å°æ—¶ " + passMinute + " åˆ† " + passSecond + " ç§’";
}
blog_live_time();
</script></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#6200ee" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" href="javascript:;" title="æœç´¢"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a><script>window.addEventListener("DOMContentLoaded", () => {
  // Handle and trigger popup window
  document.querySelector(".popup-trigger").addEventListener("click", () => {
    document.querySelector(".popup").classList.add("show");
    setTimeout(() => {
      document.querySelector(".search-input").focus();
    }, 100);
  });

  // Monitor main search box
  const onPopupClose = () => {
    document.querySelector(".popup").classList.remove("show");
  };

  document.querySelector(".popup-btn-close").addEventListener("click", () => {
    onPopupClose();
  });

  window.addEventListener("keyup", event => {
    if (event.key === "Escape") {
      onPopupClose();
    }
  });
});
</script><script defer src="https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script><script defer src="https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script><script defer src="/js/search/algolia-search.js"></script><div class="popup search-popup"><div class="search-header"><span class="popup-btn-close close-icon hty-icon-button"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-close-line"></use></svg></span></div><div class="search-input-container"></div><div class="algolia-results"><div id="algolia-stats"></div><div id="algolia-hits"></div><div class="algolia-pagination" id="algolia-pagination"></div></div></div></div><!-- hexo injector body_end start --><script src="/js/tag-common/index.js"></script><!-- hexo injector body_end end --></body></html>